{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54843e58",
   "metadata": {},
   "source": [
    "# Oracle 26ai를 Vector Store로 사용하여 Python/LangChain에서 RAG 구성하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326294a",
   "metadata": {},
   "source": [
    "## Step 1: Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd510903",
   "metadata": {},
   "source": [
    "### Step 1.1: Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7475207",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da783cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe8f53a",
   "metadata": {},
   "source": [
    "### Step 1.2: Splitting documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=256,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c0077f",
   "metadata": {},
   "source": [
    "### Step 1.3: Storing documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c917128",
   "metadata": {},
   "source": [
    "#### Text embedding\n",
    "\n",
    "LangChain 문서 다음 링크에서 여러 embedding 모델에 따른 예시를 확인할 수 있습니다.\n",
    "- https://python.langchain.com/docs/how_to/embed_text/#setup\n",
    "\n",
    "여기서는 로컬 테스트를 위해 Ollama를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a00d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"paraphrase-multilingual\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69559090",
   "metadata": {},
   "source": [
    "#### VectorStore: OracleVS vector store\n",
    "\n",
    "LangChain 문서 다음 링크에서 여러 vector store에 따른 예시를 확인할 수 있습니다.\n",
    "- https://python.langchain.com/docs/how_to/embed_text/#setup\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/\n",
    "\n",
    "여기서는 Oracle Database 26ai를 vector store로 사용합니다.\n",
    "- https://python.langchain.com/docs/integrations/vectorstores/oracle/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d008949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oracledb\n",
    "\n",
    "username = \"vector\"\n",
    "password = \"vector\"\n",
    "dsn = \"localhost:1521/FREEPDB1\"\n",
    "\n",
    "try:\n",
    "    connection = oracledb.connect(user=username, password=password, dsn=dsn)\n",
    "\n",
    "    cursor = connection.cursor()\n",
    "    cursor.callproc(\"DBMS_APPLICATION_INFO.SET_CLIENT_INFO\", (\"oracle-devday/langchain-lab\",))\n",
    "\n",
    "    print(\"Connection successful!\")\n",
    "except Exception as e:\n",
    "    print(\"Connection failed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5a5508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_oracledb.vectorstores import OracleVS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "\n",
    "vector_store = OracleVS(\n",
    "    client=connection,        \n",
    "    table_name=\"DOCUMENTS_COSINE\",\n",
    "    embedding_function=embeddings_model,\n",
    "    distance_strategy=DistanceStrategy.COSINE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eaa0c8",
   "metadata": {},
   "source": [
    "**SQL Worksheet**로 DB에 접속하여 다음을 실행합니다. (**SQLcl**은 Python Environment와 충돌하여, 동작하지 않을 수 있습니다.)\n",
    "\n",
    "```sql\n",
    "desc DOCUMENTS_COSINE;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4c46d5",
   "metadata": {},
   "source": [
    "#### Storing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf29259",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80429e8",
   "metadata": {},
   "source": [
    "**SQL Worksheet** 또는 **SQLcl**로 DB에 접속하여 다음을 실행합니다.\n",
    "\n",
    "```sql\n",
    "SELECT id, text, to_char(METADATA), EMBEDDING FROM DOCUMENTS_COSINE;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3081a",
   "metadata": {},
   "source": [
    "## Step 2: Retrieval and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3335d242",
   "metadata": {},
   "source": [
    "### Step 2.1: Retrieve Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_question = \"What is Task Decomposition?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffdbcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9b4e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(user_question)\n",
    "#print(len(retrieved_docs))\n",
    "#print(retrieved_docs)\n",
    "\n",
    "import json\n",
    "\n",
    "for index, doc in enumerate(retrieved_docs):\n",
    "    print(f\"#### index: {index}\")\n",
    "    print(f\"     metadata: {doc.metadata}\")\n",
    "    print(f\"     page_content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f7fc3a",
   "metadata": {},
   "source": [
    "### Step 2.1-1: Retrieve with Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bd424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import chain\n",
    "from typing import List\n",
    "\n",
    "@chain\n",
    "def retriever(query: str) -> List[Document]:\n",
    "    docs, scores = zip(*vector_store.similarity_search_with_score(query))\n",
    "    for doc, score in zip(docs, scores):\n",
    "        doc.metadata[\"score\"] = score\n",
    "\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1e017",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(user_question)\n",
    "#print(len(retrieved_docs))\n",
    "#print(retrieved_docs)\n",
    "\n",
    "import json\n",
    "\n",
    "for index, doc in enumerate(retrieved_docs):\n",
    "    print(f\"#### index: {index}\")\n",
    "    print(f\"     metadata: {doc.metadata}\")\n",
    "    print(f\"     page_content: {doc.page_content}\")\n",
    "    print(f\"     score: {doc.metadata['score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6246a",
   "metadata": {},
   "source": [
    "### Step 2.2: Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf166f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Respond in Korean.\n",
    "\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba498a8",
   "metadata": {},
   "source": [
    "### Step 2.3: LLM\n",
    "\n",
    "LangChain 문서 다음 링크에서 여러 chat model에 따른 예시를 확인할 수 있습니다.\n",
    "- https://python.langchain.com/docs/integrations/chat/\n",
    "\n",
    "여기서는 로컬 테스트를 위해 Ollama를 사용합니다.\n",
    "- https://python.langchain.com/docs/integrations/chat/ollama/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf5e2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    #model=\"llama3.1\",         #llama3.1:8b\n",
    "    #model=\"llama3.2:latest\",  #llama3.2:3b\n",
    "    model=\"llama3.2:1b\",\n",
    "    temperature=0,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44464440",
   "metadata": {},
   "source": [
    "### Step 2.4: Answer\n",
    "llama3.1:8b: AMD 1 OCPU - 6m 23s\n",
    "llama3.2:1b: AMD 1 OCPU - 1m 2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f70142",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "question = user_question\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(f\"# user_question: {user_question}\")\n",
    "print(f\"# response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb569396",
   "metadata": {},
   "source": [
    "## Step 3: OracleVS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e444ec3",
   "metadata": {},
   "source": [
    "**SQL Worksheet** 또는 **SQLcl**로 DB에 접속하여 다음을 실행합니다.\n",
    "앞 코드 실행으로 인해 DB에서 실행한 SQL 쿼리를 확인하는 질의입니다.\n",
    "\n",
    "```sql\n",
    "SELECT sql_id, parsing_schema_name, sql_text\n",
    "FROM v$sql\n",
    "WHERE parsing_schema_name = 'VECTOR' and module like '%python'\n",
    "ORDER BY last_active_time DESC;\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39b9eb0",
   "metadata": {},
   "source": [
    "실행한 SQL 쿼리에 대한 실행 계획을 확인합니다.\n",
    "\n",
    "- 예시\n",
    "```sql\n",
    "EXPLAIN PLAN FOR\n",
    "    SELECT id, text, metadata, vector_distance(embedding, :embedding, COSINE) as distance\n",
    "      FROM DOCUMENTS_COSINE\n",
    "  ORDER BY distance\n",
    "     FETCH APPROX FIRST 4 ROWS ONLY;\n",
    "\n",
    "SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY(format => 'ALL'));\n",
    "```\n",
    "\n",
    "생성된 테이블에 INDEX가 없으므로, FULL Search하는 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94791d45",
   "metadata": {},
   "source": [
    "### Step 3.1: Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37dccb",
   "metadata": {},
   "source": [
    "#### Step 3.1.1: HNSW Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af5cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_oracledb.vectorstores import oraclevs\n",
    "\n",
    "oraclevs.create_index(\n",
    "    connection,\n",
    "    vector_store,\n",
    "    params={\"idx_name\": \"documents_cosine_hnsw_idx\", \"idx_type\": \"HNSW\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6085dc77",
   "metadata": {},
   "source": [
    "**SQL Worksheet** 또는 **SQLcl**로 DB에 접속하여 다음을 실행합니다.\n",
    "\n",
    "```sql\n",
    "SELECT * FROM ALL_INDEXES WHERE table_name=UPPER('DOCUMENTS_COSINE');\n",
    "```\n",
    "\n",
    "인덱스가 생성된 것을 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d75a6ad",
   "metadata": {},
   "source": [
    "Step 2.4과 동일한 내용으로 LLM에 다시 요청합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9870a081",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(question)\n",
    "\n",
    "print(f\"# user_question: {user_question}\")\n",
    "print(f\"# response: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef2fe84",
   "metadata": {},
   "source": [
    "**SQL Worksheet** 또는 **SQLcl**로 DB에 접속하여 다음을 실행합니다.\n",
    "실행 계획이 달라졌는 지 확인합니다.\n",
    "\n",
    "- 예시\n",
    "```sql\n",
    "EXPLAIN PLAN FOR\n",
    "    SELECT id, text, metadata, vector_distance(embedding, :embedding, COSINE) as distance\n",
    "      FROM DOCUMENTS_COSINE\n",
    "  ORDER BY distance\n",
    "     FETCH APPROX FIRST 4 ROWS ONLY;\n",
    "\n",
    "SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY(format => 'ALL'));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84c751e",
   "metadata": {},
   "source": [
    "#### Step 3.1.2: IVF Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838dcd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oraclevs.drop_index_if_exists(\n",
    "    connection,\n",
    "    index_name=\"documents_cosine_hnsw_idx\"   \n",
    ")\n",
    "\n",
    "oraclevs.create_index(\n",
    "    connection,\n",
    "    vector_store,\n",
    "    params={\"idx_name\": \"documents_cosine_ivf_idx\", \"idx_type\": \"IVF\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a0e400",
   "metadata": {},
   "source": [
    "### Step 3.2: Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d09ce53",
   "metadata": {},
   "source": [
    "#### Step 3.2.1: Filtering - filter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50f6aac",
   "metadata": {},
   "source": [
    "필터링 없이 유사도 검색은 다음과 같이 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a227dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity search without a filter\n",
    "print(\"\\nSimilarity search results without filter:\")\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question, 2)\n",
    "\n",
    "for index, doc in enumerate(retrieved_docs):\n",
    "    print(f\"#### index: {index}\")\n",
    "    print(f\"     metadata: {doc.metadata}\")\n",
    "    print(f\"     page_content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b7259",
   "metadata": {},
   "source": [
    "similarity_search() 함수를 통해 문서 retrieved_docs를 응답으로 받는 경우, chain 말고 각 문서의 page_content의 문자열을 context로 직접 사용하는 것도 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3406675",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "question = user_question\n",
    "\n",
    "prompt = f\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "Respond in Korean.\n",
    "\n",
    "Question: {question} \n",
    "Context: {context} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "\n",
    "print(f\"# user_question: {user_question}\")\n",
    "print(f\"# response: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851692a6",
   "metadata": {},
   "source": [
    "metadata 칼럼 기준으로 아래와 같이 필터링 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity search with a filter\n",
    "print(\"\\nSimilarity search results with filter:\")\n",
    "\n",
    "# filter_criteria = {\"source\": [\"https://lilianweng.github.io/posts/2023-06-23-agent/\"]};\n",
    "filter_dict = {\"source\": \"https://lilianweng.github.io/posts/2023-06-23-agent/\"};\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search(question, 3, filter=filter_dict);\n",
    "\n",
    "for index, doc in enumerate(retrieved_docs):\n",
    "    print(f\"#### index: {index}\")\n",
    "    print(f\"     metadata: {doc.metadata}\")\n",
    "    print(f\"     page_content: {doc.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f9d96",
   "metadata": {},
   "source": [
    "**SQL Worksheet** 또는 **SQLcl**로 DB에 접속하여 다음을 실행합니다.\n",
    "\n",
    "실행된 쿼리를 확인합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e81c78",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT sql_id, parsing_schema_name, sql_text\n",
    "FROM v$sql\n",
    "WHERE parsing_schema_name = 'VECTOR' and module like '%python' and sql_text like '%DOCUMENTS_COSINE%'\n",
    "ORDER BY last_active_time DESC;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def90e28",
   "metadata": {},
   "source": [
    "실행된 쿼리를 확인해 보면 필터링이 **WHERE JSON_EXISTS**로 **Where 절 조건**이 추가된 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206d49c8",
   "metadata": {},
   "source": [
    "```sql\n",
    "SELECT id, text, metadata, vector_distance(embedding, :embedding, COSINE) as distance\n",
    "FROM \"DOCUMENTS_COSINE\"\n",
    "WHERE JSON_EXISTS(metadata, '$.source?(@ == $val)' PASSING :value0 AS \"val\")\n",
    "ORDER BY distance\n",
    "FETCH APPROX FIRST 3 ROWS ONLY\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b3d36",
   "metadata": {},
   "source": [
    "JSON 타입인 metadata에 대해서 추가적인 인덱스 설정이 필요합니다.\n",
    "\n",
    "**SQL Worksheet** 또는 **SQLcl**로 DB에 접속하여 다음을 실행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638cacf",
   "metadata": {},
   "source": [
    "```sql\n",
    "CREATE SEARCH INDEX metadata_json_search_idx\n",
    "ON DOCUMENTS_COSINE (metadata)\n",
    "FOR JSON;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f79d740",
   "metadata": {},
   "source": [
    "인덱스 생성후 다시 확인해 보면 새로운 JSON 인덱스를 사용하는 것을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac6a094",
   "metadata": {},
   "source": [
    "```sql\n",
    "EXPLAIN PLAN FOR\n",
    "  SELECT id, text, metadata, vector_distance(embedding, :embedding, COSINE) as distance\n",
    "    FROM \"DOCUMENTS_COSINE\"\n",
    "   WHERE JSON_EXISTS(metadata, '$.source?(@ == $val)' PASSING :value0 AS \"val\")\n",
    "ORDER BY distance\n",
    "   FETCH APPROX FIRST 3 ROWS ONLY;\n",
    "\n",
    "SELECT * FROM TABLE(DBMS_XPLAN.DISPLAY(format => 'ALL'));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbb0b1",
   "metadata": {},
   "source": [
    "#### Step 3.2.2: Filtering - filter : score 함께 가져오기 (참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2205ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarity search with relevance score\n",
    "print(\"\\nSimilarity search with relevance score:\")\n",
    "\n",
    "retrieved_docs = vector_store.similarity_search_with_score(question, 2);\n",
    "\n",
    "for index, doc_with_score in enumerate(retrieved_docs):\n",
    "    print(f\"#### index: {index}\")\n",
    "    #print(type(doc_with_score))\n",
    "    doc = doc_with_score[0]\n",
    "    score = doc_with_score[1]\n",
    "    print(f\"     metadata: {doc.metadata}\")\n",
    "    print(f\"     page_content: {doc.page_content}\")\n",
    "    print(f\"     score: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d530037",
   "metadata": {},
   "source": [
    "## Step 4: Existing Table with VECTOR type\n",
    "이전 내용들은 LangChain에서 문서를 읽어 분리하고, 임베딩하고 DB 테이블에 저장하는 일련의 인덱싱 작업 후에 조회하는 과정이었습니다. OracleVS 패키지 또한 LangChain 연동에 맞춰 구현된 내용으로 그에 맞게 테이블 구조가 자동으로 만들어 진 상태였습니다.\n",
    "\n",
    "여기서는 사용자가 이미 있는 테이블, 데이터에 대해 Oracle AI Database 26ai Vector Search 기능을 통해 유사도 질의를 하는 경우, LangChain에서 어떻게 사용할 까 하는 부분입니다. oracledb 패키지를 통해 Python에서 SQL 질의하고, 그 결과를 LangChain에 사용하는 langchain_core.documents.base.Document 클래스 형태로 변경하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e585c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings_model = OllamaEmbeddings(model=\"paraphrase-multilingual\")\n",
    "query_vector = embeddings_model.embed_query(\"다국어 메뉴판이 있는 여의도 맛집\")\n",
    "    \n",
    "#print(type(query_vector)) # <class 'list'>\n",
    "query_vector_str = str(query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bc1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "cursor = connection.cursor()    \n",
    "\n",
    "query = \"\"\"\n",
    "SELECT id, VECTOR_DISTANCE(VECTOR_DESCRIPTION, :query_vector, COSINE) AS vector_distance, business_type_registered, name, description\n",
    "FROM RSTR_INFO\n",
    "WHERE business_type_registered='한식'\n",
    "ORDER BY vector_distance\n",
    "FETCH FIRST 10 ROWS ONLY\n",
    "\"\"\"\n",
    "cursor.execute(query, {\"query_vector\": query_vector_str})\n",
    "results = cursor.fetchall()\n",
    "\n",
    "retrieved_docs = []\n",
    "\n",
    "for result in results:\n",
    "    metadata = {\n",
    "        \"id\": result[0],\n",
    "        \"business_type_registered\": result[2],\n",
    "        \"name\": result[3]\n",
    "        }\n",
    "            \n",
    "    doc = Document(\n",
    "        page_content=(\n",
    "            result[4]\n",
    "            if result[4] is not None\n",
    "            else \"\"\n",
    "        ),\n",
    "        metadata=metadata,\n",
    "    )\n",
    "\n",
    "    retrieved_docs.append(doc)\n",
    "\n",
    "for index, doc in enumerate(retrieved_docs):\n",
    "    print(f\"#### index: {index}\")\n",
    "    print(f\"     metadata: {doc.metadata}\")\n",
    "    print(f\"     page_content: {doc.page_content}\")\n",
    "\n",
    "print(\"\\n\".join([f\"{doc.metadata['name']}: {doc.page_content}\" for doc in retrieved_docs]))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
